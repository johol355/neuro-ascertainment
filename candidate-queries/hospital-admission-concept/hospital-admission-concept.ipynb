{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Define the SQLalchemy engine\n",
    "engine = create_engine(f\"sqlite:////Users/JO/PhD/neuro-ascertainment/data/db.sqlite\")\n",
    "\n",
    "# Read the SQL query from the file\n",
    "with open('/Users/JO/PhD/neuro-ascertainment/candidate-queries/hospital-admission-concept/hospital-admission-concept.sql', 'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "SEED = 20\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "def count_id(df):\n",
    "    LopNr = df['LopNr'].nunique() if 'LopNr' in df else 'Column missing'\n",
    "    VtfId_LopNr = df['VtfId_LopNr'].nunique() if 'VtfId_LopNr' in df else 'Column missing'\n",
    "    HADM_ID = df['HADM_ID'].nunique() if 'HADM_ID' in df else 'Column missing'\n",
    "    return print(f'Unique patients: {LopNr} | Unique SIR admits: {VtfId_LopNr} | Unique PAR admits: {HADM_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAR_HADM\n",
    "PAR_HADM contains all PAR admits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique patients: 59333 | Unique SIR admits: Column missing | Unique PAR admits: 359305\n"
     ]
    }
   ],
   "source": [
    "query_PAR_HADM = query + \"SELECT * FROM PAR_HADM\"\n",
    "PAR_HADM = pd.read_sql(query_PAR_HADM, engine)\n",
    "count_id(PAR_HADM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T_ICU_ADMISSIONS\n",
    "All ICU admissions at tertiary a ICU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique patients: 25362 | Unique SIR admits: 30335 | Unique PAR admits: Column missing\n"
     ]
    }
   ],
   "source": [
    "query_T_ICU_ADMISSIONS = query + \"SELECT * FROM T_ICU_ADMISSIONS\"\n",
    "T_ICU_ADMISSIONS = pd.read_sql(query_T_ICU_ADMISSIONS, engine)\n",
    "count_id(T_ICU_ADMISSIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T_ICU_ADMISSIONS_MATCHED_WITH_PAR\n",
    "Left join PAR admissions (with certain criteria) on T_ICU_ADMISSIONS on LopNr (patient ID) . Patients are lost at this step as they do not have a proper patient ID (\"reservnummer\").\n",
    "\n",
    "Note that each patient can have several ICU admits here. Also, each ICU admit can be matched with several PAR admits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique patients: 21806 | Unique SIR admits: 25366 | Unique PAR admits: 29486\n"
     ]
    }
   ],
   "source": [
    "query_T_ICU_ADMISSIONS_MATCHED_WITH_PAR = query + \"SELECT * FROM T_ICU_ADMISSIONS_MATCHED_WITH_PAR\"\n",
    "T_ICU_ADMISSIONS_MATCHED_WITH_PAR = pd.read_sql(query_T_ICU_ADMISSIONS_MATCHED_WITH_PAR, engine)\n",
    "count_id(T_ICU_ADMISSIONS_MATCHED_WITH_PAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T_ICU_ADMISSIONS_MATCHED_WITH_PAR_WITH_DX\n",
    "Inferred diagnosis for the PAR admit is added to T_ICU_ADMISSIONS_MATCHED_WITH_PAR. In a few cases the criteria for several DX are fulfilled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique patients: 21806 | Unique SIR admits: 25366 | Unique PAR admits: 29486\n"
     ]
    }
   ],
   "source": [
    "query_T_ICU_ADMISSIONS_MATCHED_WITH_PAR_WITH_DX = query + \"SELECT * FROM T_ICU_ADMISSIONS_MATCHED_WITH_PAR_WITH_DX\"\n",
    "T_ICU_ADMISSIONS_MATCHED_WITH_PAR_WITH_DX = pd.read_sql(query_T_ICU_ADMISSIONS_MATCHED_WITH_PAR_WITH_DX, engine)\n",
    "count_id(T_ICU_ADMISSIONS_MATCHED_WITH_PAR_WITH_DX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T_ICU_ADMISSIONS_MATCHED_WITH_PAR_WITH_DX_TIME_HIERARCHY\n",
    "This takes care of situations where a ICU admit is matched with several PAR admits. Here a column called DX_ORDER is introduced, ranking PAR admits based on \"relevancy\". The earliest admit is most relevant. If there is a tie on date, a diagnostic group hierarchy is used to decide rank. All rows with \"OTHER\" dx are removed, that's why we loose patients in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique patients: 16386 | Unique SIR admits: 19181 | Unique PAR admits: 20350\n"
     ]
    }
   ],
   "source": [
    "query_TIME_HIERARCHY= query + \"SELECT * FROM T_ICU_ADMISSIONS_MATCHED_WITH_PAR_WITH_DX_TIME_HIERARCHY\"\n",
    "TIME_HIERARCHY  = pd.read_sql(query_TIME_HIERARCHY, engine)\n",
    "count_id(TIME_HIERARCHY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s_/hnbjtb757x10k0pyf6_x_9mw0000gn/T/ipykernel_90935/2561574566.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  small_d['INDATUM'] = pd.to_datetime(small_d['INDATUM'], unit='D')\n",
      "/var/folders/s_/hnbjtb757x10k0pyf6_x_9mw0000gn/T/ipykernel_90935/2561574566.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  small_d['UTDATUM'] = pd.to_datetime(small_d['UTDATUM'], unit='D')\n",
      "/var/folders/s_/hnbjtb757x10k0pyf6_x_9mw0000gn/T/ipykernel_90935/2561574566.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  small_d['InskrTidPunkt'] = pd.to_datetime(small_d['InskrTidPunkt'], unit='s').dt.normalize()\n",
      "/var/folders/s_/hnbjtb757x10k0pyf6_x_9mw0000gn/T/ipykernel_90935/2561574566.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  small_d['UtskrTidPunkt'] = pd.to_datetime(small_d['UtskrTidPunkt'], unit='s').dt.normalize()\n",
      "/var/folders/s_/hnbjtb757x10k0pyf6_x_9mw0000gn/T/ipykernel_90935/2561574566.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['timediff_to_sir'] = filtered_df['INDATUM'] - filtered_df['InskrTidPunkt']\n"
     ]
    }
   ],
   "source": [
    "small_d = TIME_HIERARCHY[['VtfId_LopNr','InskrTidPunkt', 'UtskrTidPunkt', 'HADM_ID', 'MVO', 'LopNr', 'INDATUM', 'UTDATUM', 'DX_GROUP', 'DIAGNOS', 'DX_ORDER']]\n",
    "small_d['INDATUM'] = pd.to_datetime(small_d['INDATUM'], unit='D')\n",
    "small_d['UTDATUM'] = pd.to_datetime(small_d['UTDATUM'], unit='D')\n",
    "small_d['InskrTidPunkt'] = pd.to_datetime(small_d['InskrTidPunkt'], unit='s').dt.normalize()\n",
    "small_d['UtskrTidPunkt'] = pd.to_datetime(small_d['UtskrTidPunkt'], unit='s').dt.normalize()\n",
    "\n",
    "filtered_df = small_d[small_d.groupby('VtfId_LopNr')['VtfId_LopNr'].transform('size') > 1]\n",
    "filtered_df['timediff_to_sir'] = filtered_df['INDATUM'] - filtered_df['InskrTidPunkt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VtfId_LopNr</th>\n",
       "      <th>InskrTidPunkt</th>\n",
       "      <th>UtskrTidPunkt</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>MVO</th>\n",
       "      <th>LopNr</th>\n",
       "      <th>INDATUM</th>\n",
       "      <th>UTDATUM</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>DIAGNOS</th>\n",
       "      <th>DX_ORDER</th>\n",
       "      <th>timediff_to_sir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20788</th>\n",
       "      <td>177718.0</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>254484</td>\n",
       "      <td>301</td>\n",
       "      <td>45807.0</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>TBI</td>\n",
       "      <td>S066 S065 S028 I109 I252 Z867A</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20789</th>\n",
       "      <td>177718.0</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>254485</td>\n",
       "      <td>331</td>\n",
       "      <td>45807.0</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>TBI</td>\n",
       "      <td>S066 S062 I109 E831</td>\n",
       "      <td>2</td>\n",
       "      <td>0 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       VtfId_LopNr InskrTidPunkt UtskrTidPunkt  HADM_ID  MVO    LopNr  \\\n",
       "20788     177718.0    2021-05-03    2021-05-06   254484  301  45807.0   \n",
       "20789     177718.0    2021-05-03    2021-05-06   254485  331  45807.0   \n",
       "\n",
       "         INDATUM    UTDATUM DX_GROUP                         DIAGNOS  \\\n",
       "20788 2021-05-03 2021-05-03      TBI  S066 S065 S028 I109 I252 Z867A   \n",
       "20789 2021-05-03 2021-05-10      TBI             S066 S062 I109 E831   \n",
       "\n",
       "       DX_ORDER timediff_to_sir  \n",
       "20788         1          0 days  \n",
       "20789         2          0 days  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_vtf = rng.choice(filtered_df['VtfId_LopNr'], 1)\n",
    "filtered_df.query(f\"VtfId_LopNr == {check_vtf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T_ICU_ADMISSIONS_MATCHED_WITH_PAR_WITH_DX_HIERARCHY_TIME\n",
    "Same thing as above, but hierarchy first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique patients: 16386 | Unique SIR admits: 19181 | Unique PAR admits: 20350\n"
     ]
    }
   ],
   "source": [
    "query_HIERARCHY_TIME= query + \"SELECT * FROM T_ICU_ADMISSIONS_MATCHED_WITH_PAR_WITH_DX_HIERARCHY_TIME\"\n",
    "HIERARCHY_TIME  = pd.read_sql(query_HIERARCHY_TIME, engine)\n",
    "count_id(HIERARCHY_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s_/hnbjtb757x10k0pyf6_x_9mw0000gn/T/ipykernel_90935/2839594063.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  small_d['INDATUM'] = pd.to_datetime(small_d['INDATUM'], unit='D')\n",
      "/var/folders/s_/hnbjtb757x10k0pyf6_x_9mw0000gn/T/ipykernel_90935/2839594063.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  small_d['UTDATUM'] = pd.to_datetime(small_d['UTDATUM'], unit='D')\n",
      "/var/folders/s_/hnbjtb757x10k0pyf6_x_9mw0000gn/T/ipykernel_90935/2839594063.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  small_d['InskrTidPunkt'] = pd.to_datetime(small_d['InskrTidPunkt'], unit='s').dt.normalize()\n",
      "/var/folders/s_/hnbjtb757x10k0pyf6_x_9mw0000gn/T/ipykernel_90935/2839594063.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  small_d['UtskrTidPunkt'] = pd.to_datetime(small_d['UtskrTidPunkt'], unit='s').dt.normalize()\n",
      "/var/folders/s_/hnbjtb757x10k0pyf6_x_9mw0000gn/T/ipykernel_90935/2839594063.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['timediff_to_sir'] = filtered_df['INDATUM'] - filtered_df['InskrTidPunkt']\n"
     ]
    }
   ],
   "source": [
    "small_d = HIERARCHY_TIME[['VtfId_LopNr','InskrTidPunkt', 'UtskrTidPunkt', 'HADM_ID', 'MVO', 'LopNr', 'INDATUM', 'UTDATUM', 'DX_GROUP', 'DIAGNOS', 'DX_ORDER']]\n",
    "small_d['INDATUM'] = pd.to_datetime(small_d['INDATUM'], unit='D')\n",
    "small_d['UTDATUM'] = pd.to_datetime(small_d['UTDATUM'], unit='D')\n",
    "small_d['InskrTidPunkt'] = pd.to_datetime(small_d['InskrTidPunkt'], unit='s').dt.normalize()\n",
    "small_d['UtskrTidPunkt'] = pd.to_datetime(small_d['UtskrTidPunkt'], unit='s').dt.normalize()\n",
    "\n",
    "filtered_df = small_d[small_d.groupby('VtfId_LopNr')['VtfId_LopNr'].transform('size') > 1]\n",
    "filtered_df['timediff_to_sir'] = filtered_df['INDATUM'] - filtered_df['InskrTidPunkt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VtfId_LopNr</th>\n",
       "      <th>InskrTidPunkt</th>\n",
       "      <th>UtskrTidPunkt</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>MVO</th>\n",
       "      <th>LopNr</th>\n",
       "      <th>INDATUM</th>\n",
       "      <th>UTDATUM</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>DIAGNOS</th>\n",
       "      <th>DX_ORDER</th>\n",
       "      <th>timediff_to_sir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>125746.0</td>\n",
       "      <td>2013-12-20</td>\n",
       "      <td>2013-12-27</td>\n",
       "      <td>97114</td>\n",
       "      <td>331</td>\n",
       "      <td>17324.0</td>\n",
       "      <td>2013-12-20</td>\n",
       "      <td>2013-12-27</td>\n",
       "      <td>ICH</td>\n",
       "      <td>I614</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6435</th>\n",
       "      <td>125746.0</td>\n",
       "      <td>2013-12-20</td>\n",
       "      <td>2013-12-27</td>\n",
       "      <td>97115</td>\n",
       "      <td>109</td>\n",
       "      <td>17324.0</td>\n",
       "      <td>2013-12-27</td>\n",
       "      <td>2014-01-29</td>\n",
       "      <td>ICH</td>\n",
       "      <td>I614 I109 I489 E039</td>\n",
       "      <td>2</td>\n",
       "      <td>7 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      VtfId_LopNr InskrTidPunkt UtskrTidPunkt  HADM_ID  MVO    LopNr  \\\n",
       "6434     125746.0    2013-12-20    2013-12-27    97114  331  17324.0   \n",
       "6435     125746.0    2013-12-20    2013-12-27    97115  109  17324.0   \n",
       "\n",
       "        INDATUM    UTDATUM DX_GROUP              DIAGNOS  DX_ORDER  \\\n",
       "6434 2013-12-20 2013-12-27      ICH                 I614         1   \n",
       "6435 2013-12-27 2014-01-29      ICH  I614 I109 I489 E039         2   \n",
       "\n",
       "     timediff_to_sir  \n",
       "6434          0 days  \n",
       "6435          7 days  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_vtf = rng.choice(filtered_df['VtfId_LopNr'], 1)\n",
    "filtered_df.query(f\"VtfId_LopNr == {check_vtf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMMARY_TABLE\n",
    "Finally, using the time and dx hierarchy as tiebreakers. We choose the first ICU admit for each patient and match it with a PAR admit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_DESC_PAR = query + \"SELECT * FROM SUMMARY_TABLE\"\n",
    "DESC = pd.read_sql(query_DESC_PAR, engine)\n",
    "DESC\n",
    "\n",
    "DESC['par_adm_date'] = pd.to_datetime(DESC['par_adm_date'], unit='D')\n",
    "DESC['par_dsc_date'] = pd.to_datetime(DESC['par_dsc_date'], unit='D')\n",
    "DESC['sir_adm_time'] = pd.to_datetime(DESC['sir_adm_time'], unit='s').dt.normalize()\n",
    "DESC['sir_dsc_time'] = pd.to_datetime(DESC['sir_dsc_time'], unit='s').dt.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique patients: 16386 | Unique SIR admits: 16386 | Unique PAR admits: 16386\n"
     ]
    }
   ],
   "source": [
    "count_id(DESC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sir_total_time</th>\n",
       "      <th>SAPS_GCS</th>\n",
       "      <th>any_AMV</th>\n",
       "      <th>d30</th>\n",
       "      <th>DAOH_90</th>\n",
       "      <th>DAOH_180</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TBI</th>\n",
       "      <td>56.645415</td>\n",
       "      <td>0.264192</td>\n",
       "      <td>2842.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.711572</td>\n",
       "      <td>0.191048</td>\n",
       "      <td>43.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>4580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASAH</th>\n",
       "      <td>58.611969</td>\n",
       "      <td>0.630792</td>\n",
       "      <td>6822.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.588079</td>\n",
       "      <td>0.152751</td>\n",
       "      <td>50.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICH</th>\n",
       "      <td>60.123437</td>\n",
       "      <td>0.393707</td>\n",
       "      <td>4052.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.769262</td>\n",
       "      <td>0.315046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIS</th>\n",
       "      <td>65.313184</td>\n",
       "      <td>0.386660</td>\n",
       "      <td>2155.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.735279</td>\n",
       "      <td>0.314747</td>\n",
       "      <td>3.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFX</th>\n",
       "      <td>61.551802</td>\n",
       "      <td>0.236486</td>\n",
       "      <td>3603.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.693694</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>12.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABM</th>\n",
       "      <td>56.833066</td>\n",
       "      <td>0.441413</td>\n",
       "      <td>4095.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.731942</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>52.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDH</th>\n",
       "      <td>66.837121</td>\n",
       "      <td>0.314394</td>\n",
       "      <td>2281.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.611742</td>\n",
       "      <td>0.240530</td>\n",
       "      <td>50.5</td>\n",
       "      <td>135.5</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEP</th>\n",
       "      <td>57.295302</td>\n",
       "      <td>0.463087</td>\n",
       "      <td>1415.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.720358</td>\n",
       "      <td>0.096197</td>\n",
       "      <td>75.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TUM</th>\n",
       "      <td>52.432515</td>\n",
       "      <td>0.438650</td>\n",
       "      <td>2852.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.677914</td>\n",
       "      <td>0.190184</td>\n",
       "      <td>35.0</td>\n",
       "      <td>105.5</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HC</th>\n",
       "      <td>54.406452</td>\n",
       "      <td>0.470968</td>\n",
       "      <td>2645.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.606452</td>\n",
       "      <td>0.090323</td>\n",
       "      <td>58.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENC</th>\n",
       "      <td>53.476923</td>\n",
       "      <td>0.469231</td>\n",
       "      <td>6946.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.776923</td>\n",
       "      <td>0.176923</td>\n",
       "      <td>18.5</td>\n",
       "      <td>92.5</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVM</th>\n",
       "      <td>50.434343</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>2710.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.070707</td>\n",
       "      <td>64.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVT</th>\n",
       "      <td>46.558824</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>3691.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>50.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  sex_female  sir_total_time  SAPS_GCS   any_AMV       d30  \\\n",
       "DX_GROUP                                                                        \n",
       "TBI       56.645415    0.264192          2842.5      10.0  0.711572  0.191048   \n",
       "ASAH      58.611969    0.630792          6822.5      14.0  0.588079  0.152751   \n",
       "ICH       60.123437    0.393707          4052.0       8.0  0.769262  0.315046   \n",
       "AIS       65.313184    0.386660          2155.0      10.0  0.735279  0.314747   \n",
       "CFX       61.551802    0.236486          3603.0      15.0  0.693694  0.108108   \n",
       "ABM       56.833066    0.441413          4095.0      11.0  0.731942  0.123596   \n",
       "SDH       66.837121    0.314394          2281.5      11.0  0.611742  0.240530   \n",
       "SEP       57.295302    0.463087          1415.0       7.0  0.720358  0.096197   \n",
       "TUM       52.432515    0.438650          2852.0      11.0  0.677914  0.190184   \n",
       "HC        54.406452    0.470968          2645.0      11.0  0.606452  0.090323   \n",
       "ENC       53.476923    0.469231          6946.5      10.0  0.776923  0.176923   \n",
       "AVM       50.434343    0.535354          2710.0      15.0  0.515152  0.070707   \n",
       "CVT       46.558824    0.485294          3691.5      11.0  0.529412  0.132353   \n",
       "\n",
       "          DAOH_90  DAOH_180     n  \n",
       "DX_GROUP                           \n",
       "TBI          43.0     129.0  4580  \n",
       "ASAH         50.0     138.0  4144  \n",
       "ICH           0.0      73.0  2479  \n",
       "AIS           3.0      77.0  1919  \n",
       "CFX          12.0      91.0   888  \n",
       "ABM          52.0     140.0   623  \n",
       "SDH          50.5     135.5   528  \n",
       "SEP          75.0     161.0   447  \n",
       "TUM          35.0     105.5   326  \n",
       "HC           58.0     140.0   155  \n",
       "ENC          18.5      92.5   130  \n",
       "AVM          64.0     152.0    99  \n",
       "CVT          50.0     140.0    68  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = DESC.groupby('DX_GROUP').agg({'age': 'mean', 'sex_female': 'mean', 'sir_total_time': 'median', 'SAPS_GCS': 'median', 'any_AMV': 'mean', 'd30': 'mean', 'DAOH_90': 'median', 'DAOH_180': 'median', 'VtfId_LopNr': 'count'})\n",
    "s.rename(columns={'VtfId_LopNr': 'n'}).sort_values(by='n', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epidemiology-pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
